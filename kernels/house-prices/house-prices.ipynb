{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"target = 'SalePrice'\ntrain = pd.read_csv(r'../input/house-prices-advanced-regression-techniques/train.csv', index_col=0)\ntest = pd.read_csv(r'../input/house-prices-advanced-regression-techniques/test.csv', index_col=0)\ntest[target]=np.NaN  # Dummy\n\nfull_data = [train, test]  # List of both train and test (so that they can ba handled in the same way)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Missing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#missing data\ntotal = train.isnull().sum().sort_values(ascending=False)\npercent = (train.isnull().sum()/train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If more than 15% is missing, we remove that feature:"},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = missing_data['Percent'] > 0.15\ndf_remove = missing_data.loc[mask].copy()\ndf_remove","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in full_data:\n    dataset.drop(columns=df_remove.index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Impute the rest of missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\n## Objects:\nobject_imputer = SimpleImputer(strategy='most_frequent')\ntrain_objects = train.select_dtypes(include='object')\ntrain_objects = pd.DataFrame(object_imputer.fit_transform(train_objects), columns=train_objects.columns)\ntest_objects = test.select_dtypes(include='object')\ntest_objects = pd.DataFrame(object_imputer.transform(test_objects), columns=test_objects.columns)\n\n## Numeric:\nnumberic_imputer = SimpleImputer(strategy='mean')\ntrain_numeric = train.select_dtypes(exclude='object')\ntrain_numeric = pd.DataFrame(numberic_imputer.fit_transform(train_numeric), columns=train_numeric.columns)\n\ntest_numeric = test.select_dtypes(exclude='object')\ntest_numeric = pd.DataFrame(numberic_imputer.transform(test_numeric), columns=test_numeric.columns)\n\ntrain_index = train.index.copy()\ntest_index = test.index.copy()\ntrain = pd.concat((train_numeric, train_objects), axis=1)\ntrain.index=train_index\ntest = pd.concat((test_numeric, test_objects), axis=1)\ntest.index = test_index\nfull_data = [train,test]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Data exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.select_dtypes(include='object').describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Categorical data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.select_dtypes(include='object').nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Look at categories where the SalePrice changes much with categories."},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = train.select_dtypes(include='object').columns\n\ns = pd.Series()\nfor categorical_column in categorical_columns:\n    s[categorical_column] = train.groupby(by=categorical_column)['SalePrice'].median().std()/train['SalePrice'].std()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s.sort_values(ascending=False)[0:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_categories(key):\n    sort = train.groupby(by=key)['SalePrice'].median().sort_values(ascending=False)\n    fig,ax=plt.subplots()\n    fig.set_size_inches(16,3)\n    sns.boxplot(data=train, x=key, y='SalePrice', order=sort.index, ax=ax)\n    ax.tick_params(axis='x', rotation=70)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for category in s.sort_values(ascending=False)[0:15].keys():\n    plot_categories(key=category)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## One hot encoder\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ = pd.concat([train,test], axis=0)\ndf_ = pd.get_dummies(df_)\ndf_.shape\ntrain = df_.loc[train.index].copy()\ntest = df_.loc[test.index].copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Correlation matrix (heatmap style)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation matrix\ncorrmat = train.corr().abs()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SalePrice' correlation matrix (zoomed heatmap style)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#saleprice correlation matrix\nk = 10 #number of variables for heatmap\ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(train[cols].values.T)\nsns.set(font_scale=1.25)\n\nfig, ax = plt.subplots(figsize=(10,10))\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values, \n                 ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat['SalePrice'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Remove columns with low correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = corrmat['SalePrice'].abs() > 0.05\ncolumns = train.columns[mask]\ntrain = train[columns]\ntest = test[columns]\nfull_data = [train,test]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scatter plots between 'SalePrice' and correlated variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"#scatterplot\nsns.set()\nk=5\ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\nsns.pairplot(train[cols], size = 2.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Removing outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = train.nunique()/train.count() > 0.01  # Columns with many different values\nfor key in train.columns[mask]:\n    mask = train[key] < train[key].quantile(0.995)\n    train = train.loc[mask].copy()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scatterplot\nsns.set()\nk=8\ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\nx_vars=cols.drop('SalePrice')\nsns.pairplot(data=train[cols], x_vars=x_vars, y_vars=['SalePrice'], size = 2.5, kind='reg')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for dataset in full_data:\n#    dataset['sale_time'] = dataset['YrSold']*12 + dataset['MoSold']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#pca = PCA(n_components=2, random_state=0)\n#pca.fit(train_numeric)\n#pca.explained_variance_ratio_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Trying a simple Pipeline with polynomial regression on the numeric data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_regression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.feature_selection import VarianceThreshold\n\nselect_k_best = SelectKBest(score_func=f_regression, k=15)\nstandard_scaler = StandardScaler()\nselector = VarianceThreshold(threshold=0.9)\npolynomial_features = PolynomialFeatures(degree=3)\nlinear_regression = LinearRegression()\n\nsteps = [\n    ('scaler', standard_scaler),\n#    ('selector', selector),\n    ('polynomial_features', polynomial_features),\n    ('select_k_best', select_k_best),\n    ('linear_regression', linear_regression),\n]\n\npipeline_polynomial = Pipeline(steps=steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nrandom_forest_regressor = RandomForestRegressor(n_estimators=100)\nselector = VarianceThreshold(threshold=0.2)\n\nsteps = [\n    ('scaler', standard_scaler),\n    ('selector', selector),\n    ('estimator', random_forest_regressor),\n]\n\npipeline_random_forest = Pipeline(steps=steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data = pd.concat([train_numeric, train_one_hot], axis=1)\n#data_test = pd.concat([test_numeric, test_one_hot], axis=1)\n\ndata = train.copy()\ny=data.pop('SalePrice')\nX=data\n\ndata_test = test.copy()\n_ = data_test.pop(target)\nX_test = data_test\n\nassert not 'SalePrice' in X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\n\nxgb_regressor = XGBRegressor(n_estimators=100, max_depth=100)\n\nsteps = [\n    ('scaler', standard_scaler),\n    ('estimator', xgb_regressor),\n]\n\npipeline_xgb_regressor = Pipeline(steps=steps)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Spot checking"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipelines = {\n                'poly': pipeline_polynomial, \n                'random forest' : pipeline_random_forest, \n                'xgb': pipeline_xgb_regressor,\n}\n\nscores = {}\ncv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1)\n\nfor name, estimator in pipelines.items():\n    scores[name] = cross_val_score(estimator=estimator, X=X, y=y, cv=cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_scores = pd.DataFrame(scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots()\nsns.boxplot(data=df_scores, ax=ax);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_scores.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n# define the grid\ngrid = dict()\ngrid['estimator__n_estimators'] = [i for i in [5000]]\ngrid['estimator__max_depth'] = [i for i in [2, 10, 20]]\n\n#grid['estimator__n_estimators'] = [i for i in range(1, 2)]\ncv = RepeatedKFold(n_splits=3, n_repeats=1, random_state=0)\n\n# define the grid search\nsearch = GridSearchCV(estimator=pipeline_xgb_regressor, param_grid=grid, scoring='neg_root_mean_squared_error', n_jobs=-1, cv=cv)\n# perform the search\nsearch_result = search.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ref_error = -19854.589503095718","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"search_result.best_score_/ref_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = search_result.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict and Save"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test)\ndf_result = pd.DataFrame(data=y_pred, index=X_test.index, columns=['SalePrice'])\ndf_result.index.name='Id'\ndf_result.to_csv('my_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}