{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Train test DRY management \nHow should you keep the train and test data set seperate but still having [DRY](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself) code?\nThis is something that I have been thinking about for a while and I would be very pleased I anyone could comment or give some advices."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fake some data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_, y_ = make_regression(n_samples=1000,\n    n_features=10,\n    n_informative=5,\n    n_targets=1,\n    bias=0.0,\n    noise=0.3,\n    shuffle=True,\n    random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train-test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.33, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now the data is split into four separate items: **X_train**, **X_test**, **y_train**, **y_test**, which will make it harder to keep the code DRY.  For instance if we want to remove the first 10 rows of the train data, we will need to remove them from both **X_train** and **y_train**:"},{"metadata":{},"cell_type":"markdown","source":"## Removing the first 10 rows (we suspect that they are wrong somehow)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_ = X_train[10:]\ny_train_ = y_train[10:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Having to repeat this operation for both X and y is not very DRY. In order to handle this more elegantly we can combine **X** and **y** in the same data frame (we will of course need to separate them at a later stage again)."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.DataFrame(X_train)\ntrain['y'] = y_train\n\ntest = pd.DataFrame(X_test)\ntest['y'] = y_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can handle both **X** and **y** at the same time (more DRY):"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.iloc[10:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Adding a column...\nBut what if we should add a new column? We must do this for both training data and testing data...\nPerhaps we want to invent a new feature called **helper**:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['helper'] = np.arange(0,len(train))\ntest['helper'] = np.arange(0,len(test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So here we need to define **helper** two times, repeating some code, not good...\nI have seen a solution where you create a list with the **train** and **test** data as a solution to this:"},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets = [train, test]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then you can iterate over this list (even more DRY):"},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in datasets:\n    dataset['helper'] = np.arange(0,len(dataset))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets[1].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And if you want to modify a column in test:"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['helper'] = 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"...this will now be vissible in the **datasets** list:"},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets[1].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**BUT!** if you redefine the test dataframe (which you sometimes need to do, or do by misstake) for instance by replacing it with an empty dataframe:"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"...this operation \"loses\" the connection to the **datasets** list, since it still contain the \"old\" test dataframe: "},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets[1].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Better way?\nSo we have shown that the \"list-approach\" above can be powerfull, but that it is not a \"bullit proof\" solution.\nIs this a good way to keep your data handling code DRY? Does it have any drawbacks or is there an even better way?\n\nI think it would be nice with a solution where **train**/**test** can either be handled separately or as one combined unit. \n\nThe nicest would be if one could have everything in the same dataframe, but I cannot figure out how to get the to work???"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.DataFrame()\ntrain_ = pd.DataFrame(train)\ndata = data.append(train_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['helper'] = 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}